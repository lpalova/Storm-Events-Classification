{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Annual Damage - Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from math import factorial, sqrt\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import rv_discrete\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import Imputer, label_binarize, LabelEncoder, OneHotEncoder,\\\n",
    "MinMaxScaler, scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image  \n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats.distributions import poisson\n",
    "import pydot\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import re\n",
    "random.seed(4444)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "subset_all = pd.read_pickle('./dfs/subset_all')\n",
    "\n",
    "## Model features\n",
    "\n",
    "features = ['INJURIES', 'DEATHS', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', \n",
    "            'EVENT_CATEGORY', 'BEGIN_YEAR', 'DURATION', 'STATE']\n",
    "df = subset_all[features]\n",
    "feat_cat = ['EVENT_CATEGORY', 'STATE']\n",
    "for item in feat_cat:\n",
    "    df[item] = df[item].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INJURIES 0.0\n",
      "DEATHS 0.0\n",
      "DAMAGE_PROPERTY 0.420281760126\n",
      "DAMAGE_CROPS 0.522487584474\n",
      "EVENT_CATEGORY 0.0\n",
      "BEGIN_YEAR 0.0\n",
      "DURATION 0.0\n",
      "STATE 0.0\n",
      "Percentage of data with damage property&crops info:  45.7573221454\n",
      "INJURIES              int64\n",
      "DEATHS                int64\n",
      "DAMAGE_PROPERTY     float64\n",
      "DAMAGE_CROPS        float64\n",
      "EVENT_CATEGORY     category\n",
      "BEGIN_YEAR            int64\n",
      "DURATION            float64\n",
      "STATE              category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "l = 1.0*len(df)\n",
    "for name in df.columns.values:\n",
    "    ln = len(df[df[name].isnull()])\n",
    "    print name, ln/l\n",
    "\n",
    "dfn = df.dropna()\n",
    "print 'Percentage of data with damage property&crops info: ', 100.0*len(dfn)/len(df)\n",
    "print dfn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of train data:  72.4070419074\n"
     ]
    }
   ],
   "source": [
    "dfn_trainvalid = dfn.loc[dfn.BEGIN_YEAR < 2013, :]\n",
    "dfn_test = dfn.loc[dfn.BEGIN_YEAR >= 2013, :]\n",
    "print 'Percentage of train data: ', 100.0*len(dfn_trainvalid)/len(dfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Stats - Bootstrap - By Event Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mean_stats(df, main_col):\n",
    "    return df.groupby([main_col]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_CI(col, size=1000):\n",
    "    n = len(col)\n",
    "    mean_list = []\n",
    "    for i in range(size):\n",
    "        sample = col.iloc[np.random.randint(0, n, size=round(n*0.3/0.7))]\n",
    "        mean_list.append(sample.mean())\n",
    "    mean_list = np.array(sorted(mean_list))\n",
    "    mean = np.mean(mean_list)\n",
    "    return (mean, np.percentile(mean_list,2.5), np.percentile(mean_list,97.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_means(df, main_col, damage_features):\n",
    "    predictions = defaultdict(dict)\n",
    "    for category in df[main_col].unique():\n",
    "        for feature in damage_features:\n",
    "            data = df.loc[df[main_col] == category, feature]\n",
    "            predictions[feature][category] = get_CI(data)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_accuracy(results, predictions):\n",
    "    count = 0\n",
    "    for category in results.index.values:\n",
    "        for feature in results.columns.values:\n",
    "            value = results.ix[category,feature]\n",
    "            val_tuple = predictions[feature][category]\n",
    "            if (val_tuple[1] <= float(value)) & (float(value) <= val_tuple[2]):\n",
    "                count += 1\n",
    "    dims = (results.shape[0])*(results.shape[1])\n",
    "    return 1.0*count/dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "damage_features = ['INJURIES','DEATHS','DAMAGE_PROPERTY','DAMAGE_CROPS']\n",
    "main_col = 'EVENT_CATEGORY'\n",
    "target_cols = [main_col] + damage_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "predictions = bootstrap_means(dfn_trainvalid, main_col, damage_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'dict'>, {'DAMAGE_PROPERTY': {'Winter Weather': (16409.293089884934, 9057.1959621061505, 32045.557215796129), 'Tornado': (1394011.5694426298, 727004.18906854768, 2452513.6943633566), 'Hurricane': (99885538.39662984, 43874543.566298351, 179897947.48825967), 'Tide': (127349.22784030419, 28348.531844106466, 277167.39096958167), 'Flood': (4218542.9562857104, 534757.17556598166, 15844815.069229176), 'Heat': (271989.84160483244, 122117.65558117036, 516283.10945729114), 'Storm': (146845.89754942316, 102753.91702977022, 200945.51088597966), 'Wind': (101640.85176973206, 55099.96991354927, 165336.8764382785)}, 'DAMAGE_CROPS': {'Winter Weather': (119331.6861215736, 60700.499698023974, 208951.27612657391), 'Tornado': (26768.970705190808, 15230.751181045398, 53298.625723458128), 'Hurricane': (15350691.950143648, 8947103.6475138124, 24151089.812430941), 'Tide': (7.6476045627376443, 0.0, 33.764258555133082), 'Flood': (186424.26955380329, 125524.98695813313, 274963.91186018672), 'Heat': (495967.26578946674, 333127.71013166587, 746787.07283341198), 'Storm': (26061.000126762585, 21065.998764803797, 31761.339462041058), 'Wind': (18725.750875927471, 13095.7327970321, 25042.900424746702)}, 'INJURIES': {'Winter Weather': (0.068842701367552273, 0.050118983071269357, 0.09314265919633713), 'Tornado': (0.82717561946102369, 0.5071351058057515, 1.2611774281063484), 'Hurricane': (2.035353591160221, 0.11049723756906077, 8.4198895027624303), 'Tide': (0.09558631178707222, 0.009866920152091254, 0.2981178707224334), 'Flood': (0.1786215792320173, 0.081521092482422938, 0.30515819361817198), 'Heat': (0.28437338367154313, 0.17768050967437471, 0.4260547428032091), 'Storm': (0.035187957984961826, 0.028717450781563892, 0.042857347848546883), 'Wind': (0.029669947112497333, 0.022607470117592357, 0.039350336116546231)}, 'DEATHS': {'Winter Weather': (0.014653774323754445, 0.012530875353936984, 0.016928730646424483), 'Tornado': (0.078370410562488696, 0.045758726713691446, 0.13313438234762162), 'Hurricane': (0.13403314917127071, 0.049723756906077346, 0.25966850828729282), 'Tide': (0.0367809885931559, 0.01596958174904943, 0.078346007604562715), 'Flood': (0.024047268793942672, 0.020551649540292049, 0.028177393185505679), 'Heat': (0.035556111373289283, 0.027463426144407738, 0.044926852288815482), 'Storm': (0.0059539479977806266, 0.0051461725371649419, 0.0068690569575449133), 'Wind': (0.0057562137972452, 0.0049206687460043785, 0.006722815242449485)}})\n"
     ]
    }
   ],
   "source": [
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                INJURIES    DEATHS  DAMAGE_PROPERTY  DAMAGE_CROPS\n",
      "EVENT_CATEGORY                                                   \n",
      "Flood           0.179770  0.024013     4.291519e+06  1.863786e+05\n",
      "Heat            0.282906  0.035717     2.745186e+05  4.932792e+05\n",
      "Hurricane       2.186761  0.134752     1.008096e+08  1.530431e+07\n",
      "Storm           0.035160  0.005986     1.478084e+05  2.600693e+04\n",
      "Tide            0.095797  0.035842     1.271405e+05  7.233627e+00\n",
      "Tornado         0.839780  0.076893     1.391808e+06  2.666468e+04\n",
      "Wind            0.029840  0.005737     1.030949e+05  1.862461e+04\n",
      "Winter Weather  0.068832  0.014665     1.664656e+04  1.206561e+05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = get_mean_stats(dfn_trainvalid, main_col)[damage_features]\n",
    "print results, '\\n'\n",
    "#print bootstrap_accuracy(results, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_CATEGORY</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>Flood</td>\n",
       "      <td>86.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>Heat</td>\n",
       "      <td>93.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabama</td>\n",
       "      <td>Storm</td>\n",
       "      <td>276.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alabama</td>\n",
       "      <td>Tide</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE EVENT_CATEGORY   COUNT\n",
       "0  alabama          Flood   86.25\n",
       "1  alabama           Heat   93.15\n",
       "2  alabama      Hurricane    9.60\n",
       "3  alabama          Storm  276.40\n",
       "4  alabama           Tide    1.20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stormcounts = pd.read_csv(\"./dfs/avestormcounts.csv\")\n",
    "stormcounts = stormcounts.loc[stormcounts.EVENT_CATEGORY != 'Other',:]\n",
    "stormcounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ave_col(row, storm_dict):\n",
    "    return row[2]*storm_dict[row[1]][0]\n",
    "\n",
    "def CIlower_col(row, storm_dict):\n",
    "    return row[2]*storm_dict[row[1]][1]\n",
    "\n",
    "def CIupper_col(row, storm_dict):\n",
    "    return row[2]*storm_dict[row[1]][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for key in predictions:\n",
    "#    stormcounts[key] = stormcounts.apply(func = ave_col, axis = 1, storm_dict = predictions[key])\n",
    "#    stormcounts[key+\"_LOWER\"] = stormcounts.apply(func = CIlower_col, axis = 1, storm_dict = predictions[key])\n",
    "#    stormcounts[key+\"_UPPER\"] = stormcounts.apply(func = CIupper_col, axis = 1, storm_dict = predictions[key])\n",
    "#print stormcounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2 -- Simply take the average total #INJURIES etc. per year per STATE per EVENT_CATEGORY; model independent of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test = dfn_trainvalid.groupby(['BEGIN_YEAR','STATE','EVENT_CATEGORY']).sum().reset_index()\n",
    "#sel = test[ (test.STATE == 'missouri') & (test.BEGIN_YEAR == 2011) & (test.EVENT_CATEGORY == 'Storm')]\n",
    "#sel\n",
    "#test2 = test.groupby(['STATE','EVENT_CATEGORY']).median().reset_index()\n",
    "#test2[ (test2.STATE == 'missouri')& (test2.EVENT_CATEGORY == 'Storm') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STATE EVENT_CATEGORY  INJURIES  DEATHS  DAMAGE_PROPERTY  DAMAGE_CROPS  \\\n",
      "0  alabama          Flood       0.0     1.0         763800.0           0.0   \n",
      "1  alabama           Heat       0.5     0.0              0.0           0.0   \n",
      "\n",
      "   INJURIES_LOWER  DEATHS_LOWER  DAMAGE_PROPERTY_LOWER  DAMAGE_CROPS_LOWER  \\\n",
      "0             0.0           0.0                85164.0                 0.0   \n",
      "1             0.0           0.0                    0.0                 0.0   \n",
      "\n",
      "   INJURIES_UPPER  DEATHS_UPPER  DAMAGE_PROPERTY_UPPER  DAMAGE_CROPS_UPPER  \\\n",
      "0            3.20           5.2           2.746282e+08           5158840.0   \n",
      "1          165.65          10.1           3.929450e+04            237962.5   \n",
      "\n",
      "      AREA  DAMAGE_PROPERTY_PER_AREA  \n",
      "0  52420.0                 14.570775  \n",
      "1  52420.0                  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Get the sum (on damage_features) per year, state, per event category\n",
    "dfdam = dfn_trainvalid.groupby(['BEGIN_YEAR','STATE','EVENT_CATEGORY']).sum()[damage_features]\n",
    "dfdam = dfdam.reset_index()\n",
    "# Calculate the 5th percentile, median and 95th percentile of these damages\n",
    "dfCIlower = dfdam.groupby(['STATE','EVENT_CATEGORY']).quantile(q=0.05)[damage_features]\n",
    "dfCIlower.rename(columns=lambda x: x+\"_LOWER\", inplace=True)\n",
    "dfCIlower = dfCIlower.reset_index()\n",
    "dfCIupper = dfdam.groupby(['STATE','EVENT_CATEGORY']).quantile(q=0.95)[damage_features]\n",
    "dfCIupper.rename(columns=lambda x: x+\"_UPPER\", inplace=True)\n",
    "dfCIupper = dfCIupper.reset_index()\n",
    "dfdam = dfdam.groupby(['STATE','EVENT_CATEGORY']).median()[damage_features]\n",
    "dfdam = dfdam.reset_index()\n",
    "merged = dfdam.merge(dfCIlower, on = ['STATE','EVENT_CATEGORY'])\n",
    "merged = merged.merge(dfCIupper, on = ['STATE','EVENT_CATEGORY'])\n",
    "\n",
    "areadf = pd.read_csv(\"./data/state_areas.csv\", \n",
    "                    dtype = {'AREA' : float, 'STATE' : str})\n",
    "areadf.STATE = areadf.STATE.str.lower()\n",
    "merged = pd.merge(merged,areadf,on='STATE')\n",
    "merged['DAMAGE_PROPERTY_PER_AREA'] = merged.DAMAGE_PROPERTY/merged.AREA\n",
    "print merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alabama',50.5387256772],\n",
      "['alaska',0.0],\n",
      "['american samoa',0.0],\n",
      "['arizona',0.622984472322],\n",
      "['arkansas',78.3952312003],\n",
      "['california',9.37502672653],\n",
      "['colorado',13.842584587],\n",
      "['connecticut',31.9109687895],\n",
      "['delaware',208.94837284],\n",
      "['district of columbia',0.0],\n",
      "['florida',74.3720535904],\n",
      "['georgia',3.22238115271],\n",
      "['hawaii',0.0],\n",
      "['idaho',0.0531297490696],\n",
      "['illinois',18.7163725524],\n",
      "['indiana',39.6820428336],\n",
      "['iowa',83.4030974002],\n",
      "['kansas',37.5566980238],\n",
      "['kentucky',3.83092456939],\n",
      "['louisiana',15.5312344878],\n",
      "['maine',22.5049462973],\n",
      "['maryland',16.1188134773],\n",
      "['massachusetts',187.464894827],\n",
      "['michigan',17.5571271998],\n",
      "['minnesota',10.0682168492],\n",
      "['mississippi',47.6090188305],\n",
      "['missouri',20.2480382171],\n",
      "['montana',4.42981501632],\n",
      "['nebraska',170.064642913],\n",
      "['nevada',2.12576420794],\n",
      "['new hampshire',22.0333725532],\n",
      "['new jersey',121.682907257],\n",
      "['new mexico',8.01028374044],\n",
      "['new york',7.29456511777],\n",
      "['north carolina',36.7741875546],\n",
      "['north dakota',25.1562632606],\n",
      "['ohio',276.769508767],\n",
      "['oklahoma',214.849318302],\n",
      "['oregon',1.48990130007],\n",
      "['pennsylvania',14.413080297],\n",
      "['puerto rico',3.45305164319],\n",
      "['rhode island',65.1877022654],\n",
      "['south carolina',30.3988132417],\n",
      "['south dakota',35.0033067068],\n",
      "['tennessee',17.5790503986],\n",
      "['texas',86.8348746817],\n",
      "['utah',2.81753183269],\n",
      "['vermont',252.418885191],\n",
      "['virginia',14.1347878434],\n",
      "['washington',13.5417543269],\n",
      "['west virginia',12.471110194],\n",
      "['wisconsin',57.9200332845],\n",
      "['wyoming',7.18258309223],\n"
     ]
    }
   ],
   "source": [
    "# Test print for EVENT_CATEGORY == Storm, predicted DAMAGE_PROPERTY_PER_AREA based on the simple model\n",
    "dam_property_storm = merged.loc[merged.EVENT_CATEGORY == 'Storm',:]\n",
    "dam_property_storm = dam_property_storm[['STATE','DAMAGE_PROPERTY_PER_AREA']]\n",
    "for index, row in dam_property_storm.iterrows():\n",
    "    row_string = '[\\'' + str(row['STATE']) +'\\',' + str(row['DAMAGE_PROPERTY_PER_AREA']) + '],'\n",
    "    print row_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_simple_predictions(merged, damage_features):\n",
    "    predictions_simple = defaultdict(dict)\n",
    "    for index, row in merged.iterrows():\n",
    "        for feature in damage_features:\n",
    "            ci_lower = feature + '_LOWER'\n",
    "            ci_upper = feature + '_UPPER'\n",
    "            predictions_simple[feature][(row['STATE'],row['EVENT_CATEGORY'])]=\\\n",
    "                (row[ci_lower],row[ci_upper])\n",
    "    return predictions_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simple_accuracy(dftest, predictions, damage_features):\n",
    "    success = 0\n",
    "    for index, row in dftest.iterrows():\n",
    "        for feature in damage_features:\n",
    "            pred = predictions[feature][(row['STATE'],row['EVENT_CATEGORY'])]\n",
    "            if pred[0] <= row[feature] and row[feature] <= pred[1]:\n",
    "                success += 1\n",
    "    return 1.0*success/(len(damage_features)*len(dftest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for years 2013, 2014 and 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_13 = dfn_test.loc[dfn.BEGIN_YEAR == 2013,:]\n",
    "test_14 = dfn_test.loc[dfn.BEGIN_YEAR == 2014,:]\n",
    "test_15 = dfn_test.loc[dfn.BEGIN_YEAR == 2015,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test on 2013\n",
    "bystevent13 = test_13.groupby(['STATE','EVENT_CATEGORY']).sum()[damage_features]\n",
    "bystevent13 = bystevent13.reset_index()\n",
    "bystevent13 = bystevent13[ bystevent13.STATE != 'virgin islands']\n",
    "# Test on 2014\n",
    "bystevent14 = test_14.groupby(['STATE','EVENT_CATEGORY']).sum()[damage_features]\n",
    "bystevent14 = bystevent14.reset_index()\n",
    "bystevent14 = bystevent14[ bystevent14.STATE != 'virgin islands']\n",
    "# Test on 2015\n",
    "bystevent15 = test_15.groupby(['STATE','EVENT_CATEGORY']).sum()[damage_features]\n",
    "bystevent15 = bystevent15.reset_index()\n",
    "bystevent15 = bystevent15[ bystevent15.STATE != 'virgin islands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.633254716981\n",
      "0.633844339623\n",
      "0.624410377358\n"
     ]
    }
   ],
   "source": [
    "predictions = get_simple_predictions(merged, damage_features)\n",
    "print get_simple_accuracy(bystevent13, predictions, damage_features)\n",
    "print get_simple_accuracy(bystevent14, predictions, damage_features)\n",
    "print get_simple_accuracy(bystevent15, predictions, damage_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
